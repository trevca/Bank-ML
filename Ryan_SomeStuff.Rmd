---
title: "STA141_FP"
author: "Ryan Buchner"
date: "12/1/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse)
library(randomForest)
library(missForest)
library(PCAmixdata)
library(gbm)
library(pROC)
library(ROSE)
library(Hmisc)
library(rBayesianOptimization)
library(plotly)
library(GPfit)
library(lintools)
library(gridExtra)
```

Read in data with specifications
```{r}
bank_data=read_delim("../../Downloads/bank-additional/bank-additional.csv",";",col_names=TRUE,col_types = "dfffffffcfddddfdddddf")#,col_types = "dffccffffcddddfdddddf")
```

Change the response variable to numeric.
```{r}
bank_data$y=ifelse(bank_data$y=="yes",1,0)
```

Removing call duration since technically we wouldn't know this before we called them up.
```{r}
bank_data=within(bank_data,rm("duration"))
```

Replace unknowns with NA
```{r}
bank_data[bank_data=="unknown"]=NA
```

Education has a logical order to it so we can convert it to a numeric. This works for trees, but not necessarily for neural networks or regression since the distances between the levels which we made all equal to 1 are arbitrary.
```{r}
bank_data$education=ifelse(bank_data$education=="illiterate",0,ifelse(bank_data$education=="basic.4y",1,ifelse(bank_data$education== "basic.6y",2,ifelse(bank_data$education== "basic.9y",3,ifelse(bank_data$education== "high.school",4,ifelse(bank_data$education== "university.degree",5,ifelse(bank_data$education== "professional.course",0,NA)))))))
bank_data$education=as.numeric(bank_data$education)
mean=mean(bank_data$education,na.rm=TRUE) 
bank_data$education[which(is.na(bank_data$education))]=mean
```

Mode impute the Job
```{r}
bank_data$job=impute(bank_data$job,fun=mode)
```

Appears to be a correlation between job and education, doesn't appear strong enough to justify removing one. And as we will see, neither end up as super important variables anyways.
```{r}
names=c()
means=c()
for (i in 1:11){
  job=as.character(unique(bank_data$job)[i])
  names=c(names,job)
  means=c(means,mean(bank_data[which(bank_data$job==job),]$education))
}
boxplot(means~names,data=data.frame(names=names,means=means),las=2,xlab="")
rm(job)
rm(unemployed)
rm(names)
rm(means)
rm(i)
rm(mean)
```

Default has one occurence of "yes" so it won't be a good predictor. If ever used, will cause overfitting of "yes" individuals. Might want to reconsider once looking at fill data set since that might have more "yes" occurences to the point where we can reasonably include it.
```{r}
unique(bank_data$default)
length(which(bank_data$default=="yes"))
bank_data=within(bank_data,rm("default"))
```

Analyze the 
```{r}
econ=data.frame(emp=bank_data$nr.employed,evr=bank_data$emp.var.rate,eur=bank_data$euribor3m,pri=bank_data$cons.price.idx ,conf=bank_data$cons.conf.idx)
cor(econ)
rm(econ)
```

Too much correlation between the nr.employed, emp.var.rate, and euribor3m, so we will remove two of them. Since they all provide essentially the same information, removing them will force the model to make predictions off other variables as well.
```{r}
bank_data=within(bank_data,rm("nr.employed"))
bank_data=within(bank_data,rm("emp.var.rate"))
```

Even though p-outcome is dominated by "non-existent," it seems that there are enough of yes/no in each of the categories to avoid overfitting.
```{r}
ggplot(bank_data,aes(x=poutcome,fill=as.factor(y)))+geom_bar()
```

There is some order to day of the week, so we changed it to a numeric variable, and then mean imputed to fill in missing data. However, we tested using this as a categorical variable as well and it appeared to make no difference.
```{r}
bank_data$day_of_week=ifelse(bank_data$day_of_week=="mon",0,ifelse(bank_data$day_of_week=="tue",1,ifelse(bank_data$day_of_week=="wed",2,ifelse(bank_data$day_of_week=="thu",3,ifelse(bank_data$day_of_week== "fri",4,NA)))))
bank_data$day_of_week=as.numeric(bank_data$day_of_week)
bank_data$day_of_week=as.numeric(bank_data$day_of_week)
mean=mean(bank_data$day_of_week,na.rm=TRUE)
bank_data$day_of_week[which(is.na(bank_data$day_of_week))]=mean#mean imputation
```

Housing is equally distributed between yes and no. No clear way to proceed with the missing values here through mode imputation, so it seems the best option will be to leave unknown as its own category.
```{r}
ggplot(bank_data,aes(x=housing,fill=as.factor(y)))+geom_bar()
bank_data$housing[which(is.na(bank_data$housing))]="unknown"
```

Will be best to leave unknown as its own category here. Enoguh data points where we can justify leaving it as its own category.
```{r}
ggplot(bank_data,aes(x=loan,fill=as.factor(y)))+geom_bar()
bank_data$loan[which(is.na(bank_data$loan))]="unknown"
length(which(bank_data$loan=="unknown"))
```

Good distribution of data, but very few unknowns to the point where leaving them as their own category could cause overfitting. Instead we propose mode imputation.
```{r}
ggplot(bank_data,aes(x=marital,fill=as.factor(y)))+geom_bar()
length(which(is.na(bank_data$marital)))
bank_data$marital=impute(bank_data$marital,fun=mode)
```

To avoid overfitting, we will make this categorical with 2 categories,<999 and >=999. This is because there are two strong groups but if we look at the individual counts of the data, it makes more sense to This does have a strong correaltion with poutcome though so removal is a possibility.
```{r}
ggplot(bank_data,aes(x=pdays,fill=as.factor(y)))+geom_histogram()
ggplot(bank_data[which(bank_data$pdays<900),],aes(x=pdays,fill=as.factor(y)))+geom_histogram()
bank_data$pdays=as.factor(ifelse(bank_data$pdays<999,"recent","long_ago"))
ggplot(bank_data,aes(x=pdays,fill=as.factor(y)))+geom_bar()
ggplot(bank_data,aes(x=pdays,fill=poutcome))+geom_bar()
```

Nothing we expect to be correlated with contact, so no filtering to do here.
```{r}
ggplot(bank_data,aes(x=contact,fill=as.factor(y)))+geom_bar()
```

Month data seems alright, except some of the months lack data points, which could lead to overfitting. As a result, we will assign all december cases to a joint Nov/Dec variable. Similarily, we with add March and April together, and September and October.
```{r}
ggplot(bank_data,aes(x=month,fill=as.factor(y)))+geom_bar()
length(which(bank_data$month=="dec" & bank_data$y==0))
bank_data$month[which(bank_data$month=="nov" | bank_data$month=="dec")]="nov/dev"
bank_data$month[which(bank_data$month=="sept" | bank_data$month=="oct")]="sept/oct"
bank_data$month[which(bank_data$month=="mar" | bank_data$month=="apr")]="mar/apr"
ggplot(bank_data,aes(x=month,fill=as.factor(y)))+geom_bar()
bank_data$month=as.factor(bank_data$month)
```

Not enough 3's, 4's, 5's, and 6's. Will merge those 4 together to create a more robust model.
```{r}
ggplot(bank_data,aes(x=previous,fill=as.factor(y)))+geom_bar()
length(which(bank_data$previous>=3))
bank_data$previous[which(bank_data$previous>=3)]=3
```

Set up for boosting, split into train/test sets
```{r}
tsize=400
sam=sample(4119,tsize)
test=bank_data[sam,]
train=bank_data[-sam,]
```

Look at age distribution, may want to remove outliers since they may lead to overfitting for those points in the test set. However, through cross validation we realized that removing these data points hurts the models efficiency.
```{r}
hist(train$age)
quantile(train$age)
ggplot(bank_data,aes(age,fill=as.factor(y)))+geom_histogram()
```

#Boosting

This evaluation function implement cross validation manually.
```{r}
eval<-function(shrink){
  sam2=sample(4119-tsize,4119-tsize)
  score=0
  pr=0
  for (i in 0:4){
    kfold<<-sam2[(((4119-tsize)/5)*i+1):min(((4119-tsize)/5)*(i+1),(4119-tsize))]
    tr<<-train[-kfold,]
    val<<-train[kfold,]
    tr=ovun.sample(y~.,tr,method="over",p = .5)$data
    boost=gbm(y~.,data=tr,distribution="bernoulli",n.trees=1000, shrinkage=shrink)
    pred=predict(boost,val,type="response")
    roc=roc(val$y,pred)$auc
    pred=as.numeric(ifelse(pred>.5,1,0))
    pr=pr+mean(pred==val$y)/5
    print(length(predict))
    roc=roc(val$y,pred)$auc
    score=score+roc/5
  }
  return(score)
}
```

Our kernel function for the Bayesian Optimization.
```{r}
kernel=function(X1, X2, l=1.0, sigma_f=1.0){
    sqdist =  sweep(sweep(- 2 * X1%*% t(X2),1,rowSums(X1^2),FUN="+"),2, rowSums(X2^2),FUN="+")
    return (sigma_f^2 * exp(-0.5 / l^2 * sqdist))}
```

Posterior function utilizes the above Kernel function to make predictions about the mean and variance at the points X_s. 
```{r}
posterior=function(X_s, X_train, Y_train, l=1.0, sigma_f=1.0, sigma_y=1e-8){
    K = kernel(X_train, X_train, l, sigma_f) + sigma_y^2 * diag(rep(1,nrow(X_train)))
    K_s = kernel(X_train, X_s, l, sigma_f)
    K_ss = kernel(X_s, X_s, l, sigma_f)+ 1e-8 * diag(rep(1,nrow(X_s)))
    K_inv = pinv(K)
    mu_s = t(K_s)%*%K_inv%*%Y_train

    cov_s = K_ss - t(K_s)%*%K_inv%*%K_s
    
    return (list(mu_s, cov_s))}
```

Gives us the point to sample next.
```{r}
expected_improvement=function( x_proposed,X_train, Y_train,l=1.0, sigma_f=1.0, sigma_y=.001){
    out = posterior(matrix(x_proposed,ncol=1), X_train, Y_train, l, sigma_f, sigma_y)
    mu=out[[1]]
    var=diag(out[[2]])
    y_current=max(Y_train)
    std = sqrt( var)
    delta = mu - y_current
    std[std == 0] = Inf
    z = delta / std
    return (delta * pnorm(z) + std * dnorm(z))
}
```

Set up our intial sampled points equaly spread out, and then afterwards chooses 10 more points based on the Bayesian Optimization algorithm.
```{r,message=FALSE}
vals <- seq(-4, 0, length.out = 5)
scores=c()
for (i in 1:5){
  scores=c(scores,eval(10^(vals[i])))
}
for (i in 1:10){
x_new <- seq(-4, 0, length.out = 1000)
pred <- expected_improvement(x_new,matrix(vals),matrix(scores),l=.5,sigma_f=.5,sigma_y = .01)
a= x_new[which.max(log10(pred))]
score=eval(10^a)
vals=c(vals,a)
scores=c(scores,score)
}
```

"Visualization" of Gaussian Process
```{r}
start=4
for (i in 1:11){
x_new <- seq(-4, 0, length.out = 1000)
pred <- expected_improvement(x_new,matrix(vals[1:(start+i)]),matrix(scores[1:(start+i)]),l=.5,sigma_f=.5,sigma_y = .01)
data = data.frame(x = x_new, y = log10(pred))
colnames(data)=c("x","y")
line=x_new[which.max(pred)]
#name=paste("p", toString(2*i),sep="")
assign("p2",ggplot(data,mapping=aes(x = x, y = y))+
  geom_line(color = "red", linetype = "dashed")+
  theme_minimal()+geom_vline(xintercept=line))

x_new <- seq(-4, 0, length.out = 1000)
pred <- posterior(matrix(x_new),as.matrix(vals[1:(start+i)]),matrix(scores[1:(start+i)]),l=1,sigma_f=1,sigma_y = .001)
mu <- pred[[1]]
sigma <- sqrt(diag(pred[[2]]))
data = data.frame(x = x_new, y = mu,y_up = mu + sigma, y_low = mu - sigma)
data2=data.frame(x=vals[1:(start+i)],y=matrix(scores[1:(start+i)]))
colnames(data)=c("x","y","y_up","y_low")
#name=paste("p", toString(2*i-1),sep="")
assign("p1",ggplot()+
  geom_line(data=data,color = "red", linetype = "dashed",mapping=aes(x = x, y = y))+
  geom_ribbon(data=data,fill = "skyblue", alpha = 0.5,mapping=aes(x = x, y = y,ymax = y_up, ymin = y_low)) +
  theme_minimal()+
  geom_point(data=data2,mapping=aes(x = x, y = y))+geom_vline(xintercept=line))
grid.arrange(p1,p2,ncol=2)
}
#grid.arrange(p1, p2, p3,p4,p5,p6,p7,p8,p9,p10,p11,p12,ncol=2)
```

Choose shrinkage based off Gaussian Process
```{r}
x_new <- seq(-4, 0, length.out = 1000)
pred <- posterior(matrix(x_new),as.matrix(vals),matrix(scores),l=1,sigma_f=1,sigma_y = .001)
mu <- pred[[1]]
shrink=10^x_new[which.max(mu)]
```

Oversample training set, and perform boosting. Then evaluate via AUC, accuracy, and table.
```{r}
train=ovun.sample(y~.,train,method="over",p=.5)$data
boost=gbm(y~.,data=train,distribution="bernoulli",n.trees=1000, shrinkage=.05)
summary(boost)
pred=predict(boost,test,type="response")
roc=roc(test$y,pred,plot=TRUE)
roc$auc
pred=ifelse(predict(boost,test,type="response")>.5,1,0)
mean(pred==test$y)
table(pred,test$y)
#table(c(1,1,0),c(0,0,1))
```

#Model Analysis
```{r}
predict_yes=test[which(pred==1),]
mean(test$education)
mean(predict_yes$education)
mean(test$age)
mean(predict_yes$age)
mean(test$marital=="married")
mean(predict_yes$marital=="married")
mean(test$loan=="yes")
mean(predict_yes$loan=="yes")
mean(test$housing=="yes")
mean(predict_yes$housing=="yes")
```

```{r}
hist(test$education,breaks=5)
hist(predict_yes$education,breaks=5)
hist(test$age,breaks=10)
hist(predict_yes$age,breaks=10)
```

```{r}
hist(bank_data$euribor3m)#[which(bank_data$nr.employed<5150)])
hist(bank_data$nr.employed)
hist(bank_data$emp.var.rate)
hist(bank_data$emp.var.rate[which(bank_data$euribor3m>3)])
```

#Random Forest
```{r}
sam=sample(4119,400)
train=bank_data[-sam,]
train=ovun.sample(y~.,train,method="over",p=.5)$data
test=bank_data[sam,]
rf=randomForest(y ~ ., train)
pred=predict(rf,test)
pred=ifelse(pred=="yes",1,0)
test$y=ifelse(test$y=="yes",1,0)
mean(pred==test$y)
table(pred,test$y)
rf[["confusion"]]
```

```{r}
roc=roc(test$y,pred)
plot(roc)
roc$auc
```

#PCA
```{r}
bank_data=read_delim("../../Downloads/bank-additional/bank-additional.csv",";",col_names=TRUE,col_types = "iffccffffcdddifdddddf")
```

```{r}
#
#c(2,5,10:14,16:20)
a=bank_data
a[,c(1,4,9:13,15:19)]=scale(a[,c(1,4,9:13,15:19)])
pca=PCAmix(as.matrix(a[,c(1,4,9:13,15:19)],a[,-c(1,4,9:13,15:19)],rename.level = TRUE))
```

```{r}
a$y=ifelse(a$y=="yes",1,0)
plot(pca$scores.stand[,1],pca$scores.stand[,2],col=(a$y+3))
```